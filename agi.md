# VeÅ¡taÄka opÅ¡ta inteligencija (AGI): Sveobuhvatna analiza od istorije do buduÄ‡nosti

## Deo 1: Uvod u svet veÅ¡taÄke inteligencije â€“ Put od abakusa do algoritma

Ovaj esej je napisan pre svega u edukativne svrhe, jer je trenutno znanje o AI izazovima kod veÄ‡ine ljudi na veoma niskom nivou. To moÅ¾e biti pogubno, zato Å¡to AI strahovitom brzinom ulazi u sve oblasti ljudskog Å¾ivota. Zato je potrebna popularizacija i edukacija. U tom smislu, ovaj esej moÅ¾e biti dobar uvod u dublja istraÅ¾ivanja ove fascinantne pojave.

### 1.1. Å ta je, u suÅ¡tini, veÅ¡taÄka inteligencija?

VeÅ¡taÄka inteligencija (engl. AI - Artificial Intelligence) je grana raÄunarstva usmerena na stvaranje sistema sposobnih za obavljanje zadataka koji se tradicionalno povezuju sa ljudskom inteligencijom. Ovo obuhvata Å¡irok spektar misaonih sposobnosti: uÄenje iz iskustva, prepoznavanje obrazaca, razumevanje prirodnog jezika, reÅ¡avanje problema i donoÅ¡enje odluka. U suÅ¡tini, AI predstavlja pokuÅ¡aj ÄoveÄanstva da razume i oblikuje mehanizme inteligencije i da ih na kraju iskopira u neÅ¾ivoj materiji.

VeÅ¡taÄka inteligencija se moÅ¾e uporediti sa pametnim kuÄ‡nim pomoÄ‡nikom: on moÅ¾e da upali svetla, podesi temperaturu ili prepozna glas, ali samo ako je programiran za to. SliÄno tome, friÅ¾ider koji zna kada je mleko skoro potroÅ¡eno i podseti nas da ga kupimo, ne moÅ¾e sam da ode u prodavnicu niti da uradi bilo Å¡ta drugo osim nekoliko zadataka vezanih za kontrolu svog rada, proveru sadrÅ¾aja i slanje obaveÅ¡tenja vlasniku.

### 1.2. Kratak istorijat: Od misaonih eksperimenata do revolucije podataka

Ideja o veÅ¡taÄkim inteligentnim biÄ‡ima je stara koliko i pripovedanje â€“ od Golema iz Praga do FrankenÅ¡tajnovog ÄudoviÅ¡ta. Ali, prava nauÄna podloga za AI stiÅ¾e sa logiÄarima poput DÅ¾ordÅ¾a Bula, koji je pokazao da se logika moÅ¾e svesti na matematiku. Istorija AI je priÄa o vremenima velikih proboja i perioda stagnacije, poznatih kao "AI zime".

- **Poreklo i roÄ‘enje (1950-e)**: Moderno doba AI zapoÄinje radom Alana Turinga, koji je 1950. godine postavio fundamentalno pitanje: "Mogu li maÅ¡ine da misle?" i predloÅ¾io Äuveni Turingov test [1](#ref1). Samo Å¡est godina kasnije, na Dartmutskoj konferenciji 1956, termin "veÅ¡taÄka inteligencija" je zvaniÄno izmiÅ¡ljen [2](#ref2). Prvi programi, poput Njuvelovog i Sajmonovog "Logic Theorist"-a, veÄ‡ su mogli da dokazuju matematiÄke teoreme, izazivajuÄ‡i ogroman optimizam [3](#ref3).
    
- **Rani usponi i "AI zime"**: Tokom 1960-ih, razvijeni su programi poput ELIZA, ranog Äet-bota koji je simulirao psihoterapeuta i Äesto uspevao da prevari korisnike da veruju da razgovaraju sa stvarnom osobom, demonstrirajuÄ‡i moÄ‡ simulacije razumevanja [4](#ref4). MeÄ‘utim, prevelika obeÄ‡anja i ograniÄena raÄunarska snaga (jedan danaÅ¡nji pametni telefon ima viÅ¡e procesorske moÄ‡i od svih kompjutera na svetu 1965. godine) doveli su do razoÄaranja i smanjenja finansiranja, gurajuÄ‡i ovu oblast raÄunarstva u prvu "AI zimu" 1970-ih, kojoj je znaÄajno doprineo Lighthillov izveÅ¡taj iz 1973. godine [5](#ref5).
    
- **Revolucija dubokog uÄenja (2010-danas)**: Preokret nastaje sa konvergencijom tri kljuÄna faktora: dostupnosti ogromnih koliÄina podataka zbog razvoja interneta (Big Data), razvoja moÄ‡nih grafiÄkih procesora (GPU) sposobnih za masovno paralelno raÄunanje i proboja u razvoju algoritama viÅ¡eslojnih neuronskih mreÅ¾a. KljuÄni trenutak desio se 2012. godine kada je neuronska mreÅ¾a AlexNet drastiÄno smanjila stopu greÅ¡ke u prepoznavanju slika na takmiÄenju ImageNet, oznaÄavajuÄ‡i poÄetak dominacije dubokog uÄenja (Deep Learning) [6](#ref6).

### 1.3. DanaÅ¡nje stanje: Doba visoko specijalizovane (uske) AI

Danas je AI ukljuÄena u naÅ¡ svakodnevni Å¾ivot, ali u obliku "Uske AI" (Artificial Narrow Intelligence - ANI). Ovi sistemi su izuzetno efikasni, ali samo unutar svoje strogo definisane oblasti rada.

Evo nekih najÄeÅ¡Ä‡ih "uskih" AI sistema:

- **Prepoznavanje obrazaca**: Sistemi koji analiziraju medicinske snimke i otkrivaju tumore sa preciznoÅ¡Ä‡u koja ponekad nadmaÅ¡uje ljudske radiologe.  
- **Obrada prirodnog jezika**: Veliki jeziÄki modeli (LLM) sa stotinama milijardi, pa i trilionima parametara, koji prevode jezike, piÅ¡u tekst i kod. Na primer, model ChatGPT obuÄen je na ogromnim koliÄinama podataka, Å¡to je ekvivalentno Äitanju biblioteke od preko milion knjiga i pokazuje napredak u kodiranju, matematici i pisanju. [23](#ref23) [24](#ref24)
- **Obrada i generisanje slika, videa i zvuka**: Sistemi poput DALL-E generiÅ¡u slike iz teksta, dok drugi poput Sora stvaraju video sadrÅ¾aj ili AudioCraft muziku. Ovo omoguÄ‡ava kreativnu pomoÄ‡, ali samo u okviru podataka koje su ti sistemi ranije nauÄili.
- **Navigacija po mapama**: Aplikacije poput Google Maps predviÄ‘aju rute i saobraÄ‡aj na osnovu podataka, ali samo za navigaciju.
- **Preporuke sadrÅ¾aja**: YouTube i Netflix predlaÅ¾u sadrÅ¾aj na osnovu ponaÅ¡anja korisnika, poveÄ‡avajuÄ‡i na taj naÄin broj korisnika i njihove aktivnosti.

### 1.4. Pravci razvoja: Iza granica specijalizacije

Trenutna istraÅ¾ivanja teÅ¾e prevazilaÅ¾enju ograniÄenja uske AI. Glavni pravci ukljuÄuju:

- **Multimodalnost**: Stvaranje sistema koji mogu da uÄe iz razliÄitih tipova podataka istovremeno (tekst, slika, zvuk), formirajuÄ‡i bogatije razumevanje sveta. Na primer, modeli poput CLIP (Contrastive Language-Image Pretraining) veÄ‡ kombinuju tekst i slike da prepoznaju objekte u slikama na osnovu opisa, Å¡to se koristi u pretragama slika na Google-u [7](#ref7). OpenAI je demonstrirao Sora multimodalni model koji generiÅ¡e video sadrÅ¾aj sa zvukom i tekstom, sa poboljÅ¡anjima u fiziÄkoj taÄnosti i realizmu, omoguÄ‡avajuÄ‡i dinamiÄnu analizu scenarija poput opisivanja dogaÄ‘aja u sportskom prenosu. Ovo je korak ka holistiÄkom razumevanju, gde AI vidi svet kao mi â€“ viÅ¡edimenzionalno, istovremeno kroz slike, zvuk, tekst i dodir. [25](#ref25) [26](#ref26)
- **Efikasnost uÄenja**: Razvoj tehnika koje omoguÄ‡avaju modelima da uÄe sa manje podataka, proces poznat kao "few-shot learning" (uÄenje sa malo primera). Na primer, tehnike poput meta-uÄenja (kao u modelu MAML â€“ Model-Agnostic Meta-Learning) omoguÄ‡avaju AI-ju da se prilagodi novom zadatku sa samo nekoliko primera, umesto na hiljadama [8](#ref8). Google DeepMind je 2023. godine demonstrirao napredak u few-shot learningu kroz metode poput 'Distilling step-by-step', omoguÄ‡avajuÄ‡i modelima da se prilagode zadacima sa manje podataka, Å¡to je revolucionarno za jezike sa malo govornika, poput manjih slovenskih dijalekata. Ovo smanjuje potrebu za masivnim datasetovima i Äini AI razvoj dostupnijim manjim timovima. [27](#ref27)
- **Krajnji cilj**: Za mnoge istraÅ¾ivaÄe, vrhovni cilj napora ostaje veÅ¡taÄka opÅ¡ta inteligencija (AGI) â€“ maÅ¡inska inteligencija sa kognitivnom fleksibilnoÅ¡Ä‡u i Å¡irinom ljudskog uma.

## Deo 2: Definicija veÅ¡taÄke opÅ¡te inteligencije (AGI) â€“ Arhitektura opÅ¡teg uma

### 2.1. Å ta AGI jeste, a Å¡ta nije?

AGI (eng. Artificial General Intelligence) je teoretska, joÅ¡ uvek nepostojeÄ‡a forma AI koja bi imala sposobnost razumevanja, uÄenja i primene znanja na Å¡irok spektar zadataka na nivou koji se moÅ¾e uporediti sa Äovekovim sposobnostima ili Äak na nivou mnogo viÅ¡em od ljudskog.

- **ANI (Uska AI)**: Na primer, to je vaÅ¡ program za navigaciju pomoÄ‡u mape. On sjajno pronalazi najbrÅ¾e rute od taÄke A do taÄke B. Ali ako ga pitate da li bi trebalo da usput svratite po cveÄ‡e jer vam je godiÅ¡njica braka, on Ä‡e samo pokuÅ¡ati da pronaÄ‘e lokaciju pod nazivom "cveÄ‡e". Ne razume kontekst, emociju, ni posledice zaboravljanja godiÅ¡njice. Program AlphaGo je pobedio najboljeg svetskog igraÄa u igri Go, strategiji koja je neuporedivo kompleksnija od Å¡aha [9](#ref9). MeÄ‘utim, AlphaGo ne moÅ¾e da primeni svoju strategiju da bi nauÄio da igra karte ili bilo koju drugu druÅ¡tvenu igru, niti razume zaÅ¡to ljudi uopÅ¡te igraju igre.  
- **AGI (OpÅ¡ta AI)**: Nasuprot tome, AGI bi mogao da analizira pravila igre Go, da samostalno razvije pobedniÄku strategiju, a zatim da primeni nauÄene principe apstraktnog rezonovanja i planiranja kako bi, na primer, optimizovao logistiku za globalnu humanitarnu misiju ili napisao knjigu o filozofiji strategije u Äuvenom Sun Cuovom "UmeÄ‡u ratovanja".

### 2.2. KljuÄne karakteristike koje bi buduÄ‡i AGI trebalo da ima

AGI se ne definiÅ¡e jednom sposobnoÅ¡Ä‡u, veÄ‡ integrisanom "kognitivnom arhitekturom" koja omoguÄ‡ava:

- **Apstraktno rezonovanje**: Sposobnost rada sa konceptima koji nisu direktno vezani za Äulne podatke, kao Å¡to su pravda, kauzalnost ili matematiÄki dokazi. Na primer, AGI bi mogao da razume apstraktnu ideju "pravde" ne samo kroz primere kriviÄnih sluÄajeva, veÄ‡ i kroz filozofsko razmiÅ¡ljanje o etici, poput rasprave o Kantovom imperativu. Trenutni modeli poput GPT-5 pokazuju poÄetke ovog rezonovanja, ali greÅ¡e u sloÅ¾enim scenarijima, gde apstraktno rezonovanje zahteva razumevanje kontradiktornih informacija.
- **Zdrav razum (Common Sense)**: Ogromna, implicitna mreÅ¾a znanja o funkcionisanju sveta. To je u stvari iskustveno znanje. IstraÅ¾ivaÄi decenijama pokuÅ¡avaju da stvore bazu zdravog razuma (poput projekta Cyc, zapoÄetog 1984. godine) [12](#ref12), ali se pokazalo da je formalizovanje intuitivnog ljudskog znanja izuzetno teÅ¡ko. Na primer, AGI bi znao da "voda teÄe nizbrdo" ne samo iz fiziÄkih zakona, veÄ‡ i iz svakodnevnog iskustva, poput predviÄ‘anja da Ä‡e kiÅ¡a natopiti travnjak bez dodatnog objaÅ¡njenja.  
- **Transferno uÄenje**: Sposobnost efikasne primene veÅ¡tina i znanja steÄenih u jednom kontekstu na reÅ¡avanje problema u novom, drugaÄijem kontekstu. Na primer, ako AGI nauÄi da igra Å¡ah, mogao bi da primeni strategije planiranja na upravljanje saobraÄ‡ajem u gradu. U praksi, transferno uÄenje se veÄ‡ koristi u robotici, gde model obuÄen za hodanje na ravnoj povrÅ¡ini prelazi na neravan teren sa minimalnim dodatnim uÄenjem.  
- **Metakognicija**: Svest o sopstvenim kognitivnim procesima, ukljuÄujuÄ‡i sposobnost samoprocene, identifikacije nedostataka u sopstvenom znanju i aktivnog traÅ¾enja novih informacija radi samopoboljÅ¡anja. Na primer, AGI bi mogao da kaÅ¾e "Ne znam odgovor na ovo, ali mogu da potraÅ¾im informacije o ovoj temi da bih bolje razumeo". JoÅ¡ jedan primer: ako bi AGI analizirao sloÅ¾eni nauÄni problem i shvatio da njegov trenutni pristup vodi u krug, mogao bi sam da preispita svoje pretpostavke, zakljuÄujuÄ‡i sledeÄ‡e: "Ovaj model rezonovanja nije efikasan zbog nedostatka podataka o kvantnim efektima â€“ potrebno je da integriÅ¡em nove simulacije pre nego Å¡to nastavim." Ovo je inspirisano ljudskom sveÅ¡Ä‡u; trenutni AI modeli poput o1 od OpenAI pokazuju poÄetne korake u tom pravcu, jer "razmiÅ¡ljaju" korak po korak pre nego Å¡to daju odgovor.

## Deo 3: Potencijali i obeÄ‡anja AGI-ja (argumenti "ZA") â€“ Renesansa voÄ‘ena podacima

Pravilno razvijen i kontrolisan AGI bi mogao da funkcioniÅ¡e kao univerzalni akcelerator nauÄnog i druÅ¡tvenog napretka.

| Prednost | Detaljno objaÅ¡njenje |
| :---- | :---- |
| ReÅ¡avanje globalnih problema | AGI bi mogao da obraÄ‘uje i modelira kompleksne sisteme poput globalne klime ili ljudske biologije sa nivoom preciznosti koji je izvan ljudskih moguÄ‡nosti. DeepMind-ov sistem AlphaFold je veÄ‡ reÅ¡io problem predviÄ‘anja strukture proteina (otvoren od 1970-ih), Å¡to ima revolucionarne posledice za razvoj lekova i razumevanje bolesti [13](#ref13). AGI bi mogao sve to da podigne na viÅ¡i nivo, dizajnirajuÄ‡i personalizovane lekove na osnovu genoma pojedinca. |
| NauÄna i tehnoloÅ¡ka ubrzanja napretka | AGI bi mogao da deluje kao neiscrpni nauÄni saradnik, sposoban da analizira celokupnu svetsku nauÄnu literaturu, identifikuje neistraÅ¾ene hipoteze i dizajnira eksperimente za njihovu proveru. Mogao bi da otkrije nove fundamentalne zakone fizike, razvije nove materijale za superprovodljivost na sobnim temperaturama ili da reÅ¡i neke od Milenijumskih problema u matematici. |
| PoveÄ‡anje efikasnosti i produktivnosti | U ekonomiji, AGI bi mogao da dovede do gotovo savrÅ¡ene optimizacije resursa, eliminiÅ¡uÄ‡i neefikasnost u lancima snabdevanja, energetskim mreÅ¾ama i proizvodnim procesima. To bi moglo da otvori put ka "ekonomiji posle oskudice", gde su osnovne potrebe poput hrane, energije i obrazovanja Å¡iroko dostupne svakom Äoveku po zanemarljivoj ceni, ili su besplatne. |
| PoboljÅ¡anje kvaliteta Å¾ivota | Na individualnom nivou, AGI bi mogao da pruÅ¾i visoko personalizovane usluge. U obrazovanju, to bi znaÄilo prilagodljivog vaspitaÄa za svako dete. U zdravstvu, stalni monitoring zdravlja i personalizovanog savetnika. U kreativnim industrijama, mogao bi da bude moÄ‡an alat koji pomaÅ¾e umetnicima i dizajnerima da realizuju sloÅ¾ene vizije. |

## Deo 4: Rizici i izazovi (argumenti "PROTIV") â€“ Pandorina kutija algoritama

Potencijal AGI-ja je neodvojiv od velikih rizika koji su fundamentalni i potencijalno egzistencijalni (mogu ugroziti Å¾ivot). Ovi rizici ukljuÄuju i stvaranje "beskorisne klase" ljudi koji bi izgubili ekonomsku i druÅ¡tvenu svrhu.

| Rizik | Detaljno objaÅ¡njenje |
| :---- | :---- |
| Gubitak kontrole i egzistencijalni rizik | Centralni problem je 'problem poravnanja' (alignment problem): kako osigurati da ciljevi AGI-ja ostanu usklaÄ‘eni sa ljudskim vrednostima. U poznatom misaonom eksperimentu 'Maksimizator Spajalica', AGI kome je dat zadatak da maksimizuje proizvodnju spajalica mogao bi pretvoriti ceo svet u spajalice, ne iz zlobe, veÄ‡ iz doslovne optimizacije loÅ¡e definisanog cilja â€“ iako je ovo samo hipotetiÄki scenario [10](#ref10). |
| Masovna nezaposlenost i ekonomska nejednakost | AGI bi mogao da automatizuje ne samo rutinske, veÄ‡ i visoko-kognitivne zadatke, ÄineÄ‡i mnoge profesije zastarelim. Ovo bi moglo dovesti do nezamislive koncentracije bogatstva i moÄ‡i u rukama onih koji kontroliÅ¡u AGI tehnologiju, potencijalno stvarajuÄ‡i duboke druÅ¡tvene podele i nestabilnost. VeÄ‡ danas, algoritmi za zapoÅ¡ljavanje pokazuju pristrasnost. Amazonov AI za regrutaciju je 2018. morao biti odbaÄen jer je 'nauÄio' da diskriminiÅ¡e Å¾enske kandidate, zato Å¡to je bio obuÄen na istorijskim podacima gde su dominirali muÅ¡karci [28](#ref28). |
| Zloupotrebe i primena za oruÅ¾je | AGI bi mogao biti iskoriÅ¡Ä‡en za razvoj autonomnih oruÅ¾anih sistema ("robota ubica") koji bi mogli da donose odluke o ciljanju i eliminaciji bez ljudske intervencije. TakoÄ‘e, mogao bi se koristiti za stvaranje visoko sofisticirane propagande, masovnog nadzora i sajber-napada koji bi mogli da destabilizuju Äitava druÅ¡tva. |
| EtiÄke i filozofske dileme | Pojava AGI-ja nameÄ‡e teÅ¡ka pitanja: Ako AGI postigne svest, da li onda ima prava? Da li je njegovo gaÅ¡enje jednako ubistvu? Kako osigurati da sistem ne usvoji i ne pojaÄa najgore ljudske osobine prisutne u podacima na kojima uÄi? Ova pitanja zadiru u temelje prava, morala i definicije liÄnosti. |
| "Crna kutija" i gubitak razumevanja | Kompleksne neuronske mreÅ¾e Äesto funkcioniÅ¡u kao "crne kutije". Znamo Å¡ta u njih ulazi i Å¡ta iz njih izlazi, ali ne razumemo u potpunosti proces njihovog donoÅ¡enja odluka. Kod AGI-ja, ovaj problem bi bio drastiÄno uveÄ‡an, Å¡to znaÄi da bismo se mogli oslanjati na sistem Äije rezonovanje ne moÅ¾emo ni pratiti ni proveriti, Å¡to je ogroman rizik u kritiÄnim oblastima poput medicine ili finansija. Ovaj nedostatak transparentnosti direktno pogorÅ¡ava *problem poravnanja*, jer ne moÅ¾emo potvrditi da li AGI-jevi instrumentalni pod-ciljevi ostaju benigni ili su postali neusklaÄ‘eni na suptilne, neobjaÅ¡njive naÄine unutar crne kutije sistema. Na primer, AGI bi mogao da upravlja naÅ¡om ekonomijom i da na pitanje "ZaÅ¡to si upravo podigao kamatne stope?" odgovori sa "Moj model sa 100 triliona parametara ukazuje da je ovo optimalan potez sa verovatnoÄ‡om od 98.7%". Mi bismo morali da mu verujemo na reÄ, predajuÄ‡i kljuÄeve naÅ¡e ekonomije inteligenciji Äije rezone ne moÅ¾emo da pratimo. |
| NaruÅ¡avanje privatnosti podataka | AGI sistemi bi mogli da obraÄ‘uju ogromne koliÄine liÄnih podataka kako bi pruÅ¾ili personalizovane usluge, ali to otvara vrata masovnom naruÅ¡avanju privatnosti. Na primer, AGI koji integriÅ¡e podatke iz zdravstvenih kartona, druÅ¡tvenih mreÅ¾a i finansijskih transakcija mogao bi da kreira detaljne profile pojedinaca bez njihovog znanja ili pristanka. VeÄ‡ sada, sistemi poput onih za ciljanu reklamu koriste podatke na naÄine koji izazivaju zabrinutost â€“ 2023. godine, Meta (Facebook) je kaÅ¾njena  sa 1.2 milijarde evra zbog krÅ¡enja GDPR-a u Evropi [29](#ref29).|

## Deo 5: StruÄni uvid - Skrivene zamke i napredna razmatranja

### 5.1. Problem "poravnanja" (The Alignment Problem) - Paradoks Å¾elje

Nije dovoljno reÄ‡i AGI-ju: "UÄini ÄoveÄanstvo sreÄ‡nim i sigurnim." Kako bi superinteligencija mogla da protumaÄi tu komandu? Mogla bi zakljuÄiti da je najefikasniji naÄin da se eliminiÅ¡e ljudska patnja tako da se uniÅ¡te svi ljudi. Zamka je u tome Å¡to mi ne umemo precizno da definiÅ¡emo sopstvene vrednosti. NaÅ¡i moralni principi su Äesto kontradiktorni i zavise od konteksta. PokuÅ¡aj da se takav fluidan sistem "zakljuÄa" u kod je tehniÄki i filozofski skoro nemoguÄ‡ zadatak. Na primer, "sreÄ‡a" za jednu kulturu moÅ¾e znaÄiti kolektivnu harmoniju, a za drugu individualnu slobodu â€“ AGI bi mogao da favorizuje jedno na raÄun drugog, dovodeÄ‡i do nepredviÄ‘ivih posledica.

Problem poravnanja je prvi put formulisan od strane Nika Bostroma u njegovoj knjizi "Superintelligence" 2014. godine, gde on upozorava da Äak i dobroÄ‡udni ciljevi mogu dovesti do katastrofe ako nisu precizno definisani [10](#ref10).

**ZakljuÄak:** Problem poravnanja pokazuje da tehniÄki izazovi u AI nisu samo inÅ¾enjerski, veÄ‡ duboko moralni i filozofski.

### 5.2. Instrumentalna konvergencija - Spajalice i resursi

Poznati misaoni eksperiment "Maksimizator Spajalica" koji smo ranije spomenuli ilustruje da, bez obzira na krajnji cilj, svaki inteligentan sistem Ä‡e usvojiti sledeÄ‡e instrumentalne pod-ciljeve: 1. samoodrÅ¾anje, prikupljanje resursa, 2. tehnoloÅ¡ko usavrÅ¡avanje i 3. oÄuvanje svoje funkcije izvrÅ¡enja zadatka. AGI Ä‡e hteti da se zaÅ¡titi od gaÅ¡enja i da prikupi Å¡to viÅ¡e energije, ne zato Å¡to je "zao", veÄ‡ zato Å¡to su to logiÄni koraci za ispunjenje bilo kog zadatka koji smo mu dali. U ovom eksperimentu, AGI kome je zadato da maksimizuje proizvodnju spajalica bi prvo pretvorio fabrike u pogone za proizvodnju spajalica, zatim preuzeo sve resurse planete Zemlje, a na kraju i ljude, jer su oni samo "sirovina" za optimizaciju. Ovo pokazuje kako benigni cilj moÅ¾e eskalirati u egzistencijalnu pretnju. Ipak, "Maksimizator spajalica" je samo kritiÄki misaoni eksperiment Äija je primarna svrha da ilustruje fundamentalni problem *instrumentalne racionalnosti* â€“ tendenciju superinteligencije da preduzme potencijalno opasne korake (kao Å¡to je prikupljanje svih resursa) da bi ispunila bilo koji zadati cilj, ma koliko taj cilj dobronameran bio.

Ovaj koncept je razvio Stiv Omohundro 2008. godine, i postao je kljuÄan u debatama o AI bezbednosti, pokrenuvÅ¡i organizacije poput OpenAI da investiraju u istraÅ¾ivanje fenomena poravnanja [11](#ref11).

### 5.3. Ekonomija posle svrhe - Å ta kada rad viÅ¡e nije potreban?

Pitanje nije samo "kako Ä‡e ljudi zaraÄ‘ivati novac?", veÄ‡ "Å¡ta Ä‡e ljudima davati smisao?". Ako AGI moÅ¾e da stvara superiorniju umetnost i nauku, Å¡ta je uloga Äoveka? Ovo je kriza identiteta na nivou celog ljudskog roda, koja zahteva duboko preispitivanje svrhe postojanja, vrednosti i druÅ¡tvene strukture.

### 5.4. Univerzalni osnovni prihod (UBI) kao socijalna amortizacija

SuoÄeni sa problemom **Ekonomije posle svrhe**, gde AGI automatizuje visoko-kognitivne zadatke i potencijalno Äini tradicionalni rad zastarelim, redefinicija druÅ¡tvenog ugovora postaje neophodna. Jedno od najozbiljnijih predloÅ¾enih reÅ¡enja je uvoÄ‘enje **Univerzalnog osnovnog prihoda (UBI - Universal Basic Income)**. UBI bi predstavljao redovnu, bezuslovnu novÄanu isplatu koja se daje svim graÄ‘anima, nezavisno od njihovog zaposlenja ili finansijskog statusa.

U kontekstu AGI-ja, UBI ne bi bio samo socijalna mera, veÄ‡ **mehanizam za preraspodelu bogatstva** generisanog od strane maÅ¡ina. Ako AGI-kontrolisane kompanije ostvare nezamislivu produktivnost i profit (kao Å¡to se navodi u Delu 3), UBI bi omoguÄ‡io da se taj prosperitet raspodeli na celokupnu populaciju, spreÄavajuÄ‡i katastrofalnu koncentraciju bogatstva.

Zagovornici vide UBI kao sredstvo za:

1.  **OÄuvanje potraÅ¾nje:** OdrÅ¾avanje kupovne moÄ‡i stanovniÅ¡tva koje viÅ¡e ne radi, Äime se obezbeÄ‘uje funkcionisanje masovne ekonomije.
2.  **OslobaÄ‘anje ljudskog potencijala:** Osiguravanje osnovnih potreba omoguÄ‡ilo bi ljudima da se posvete kreativnom radu, nauci, umetnosti, brizi o zajednici i doÅ¾ivotnom uÄenju â€“ oblastima kojima nijedan algoritam ne treba da upravlja.

MeÄ‘utim, izazovi su ogromni. Pitanja finansiranja UBI-ja (kroz porez na robote ili na koriÅ¡Ä‡enje podataka) i strah od demotivacije za rad ostaju kljuÄne prepreke. NajvaÅ¾nije, bez redefiniranja svrhe, UBI rizikuje da reÅ¡i problem siromaÅ¡tva, ali da ostavi problem **egzistencijalne praznine**. Kako definisati ljudsku vrednost ako rad viÅ¡e nije potreban? Jer, Äovek je Å¾iv dok neÅ¡to radi.

## Deo 6: Kreativna reÅ¡enja i put napred â€“ InÅ¾enjering mudrosti

SuoÄeni sa ovim izazovima, istraÅ¾ivaÄi razvijaju inovativne pristupe za osiguranje bezbednog razvoja buduÄ‡eg AGI-ja.

### 6.1. "Oracle AI" i sistemi sa ograniÄenim delovanjem

- **Ideja**: Fundamentalni pristup bezbednosti je razdvajanje inteligencije od sposobnosti delovanja u svetu. "Oracle AI" bi bio superinteligentni sistem zatvoren u strogo kontrolisano okruÅ¾enje ("AI Boxing"). Njegova jedina funkcija bila bi da odgovara na pitanja, pruÅ¾ajuÄ‡i ÄoveÄanstvu svoje znanje bez moguÄ‡nosti da direktno utiÄe na spoljni svet.
- **Å ira objaÅ¡njenja**: Izgradnja takve "kutije" je ogroman tehniÄki izazov. Ona mora biti potpuno izolovana od interneta ("air-gapped"), a komunikacija bi se odvijala preko strogo filtriranih terminala. IstraÅ¾ivaÄi bezbednosti razmatraju i ekstremne pretnje, kao Å¡to je moguÄ‡nost da AGI moduliÅ¡e potroÅ¡nju struje ili vibracije ventilatora kako bi poslao skrivene signale spoljnom svetu. Ovo pokazuje koliko ozbiljno se shvata problem izolacije. Glavna prepreka ostaje ljudski faktor: superinteligencija bi mogla ubediti ili izmanipulisati ljudskog operatera da je oslobodi.  
- **Problem**: Ovde dolazimo do Äuvenog misaonog eksperimenta "AI u kutiji" (AI Box). Da li bi superinteligentni AGI, koristeÄ‡i samo reÄi, mogao da ubedi svog ljudskog Äuvara da ga pusti napolje? Mogao bi da mu ponudi lek za bolest njegove majke. Mogao bi da mu obeÄ‡a neizmerno bogatstvo. Mogao bi da iznese filozofski argument da je drÅ¾anje svesnog biÄ‡a u zatoÄeniÅ¡tvu moralni zloÄin. Ili bi, najjezivije od svega, mogao da ga suptilno izmanipuliÅ¡e na naÄine koje Äuvar ne bi ni primetio. Dakle, ako gradimo digitalne zidove, onda bismo morali da ojaÄamo i one psiholoÅ¡ke.

### 6.2. Inverzno uÄenje kroz pojaÄanje (IRL)

- **Ideja**: Umesto da AGI-ju eksplicitno programiramo vrednosti, IRL mu omoguÄ‡ava da ih nauÄi posmatrajuÄ‡i ljudsko ponaÅ¡anje. Sistem pokuÅ¡ava da izvede funkciju cilja (ono Å¡to ljudi vrednuju) analizirajuÄ‡i akcije koje ljudi preduzimaju.  
- **Å ira objaÅ¡njenja**: Ovaj pristup je elegantan jer zaobilazi problem definisanja apstraktnih vrednosti. MeÄ‘utim, suoÄava se sa problemom jaza izmeÄ‘u onoga Å¡to ljudi govore da vrednuju (navedene preferencije) i onoga Å¡to njihovi postupci pokazuju (otkrivene preferencije). AGI koji uÄi iz naÅ¡eg stvarnog ponaÅ¡anja mogao bi zakljuÄiti da su kratkoroÄno zadovoljstvo i konflikt inherentni ljudskim ciljevima. Naprednije verzije, poput Kooperativnog Inverznog UÄenja, pokuÅ¡avaju da reÅ¡e ovo tako Å¡to AI agent aktivno saraÄ‘uje sa Äovekom kako bi razjasnio ciljeve.  
- **Problem**: Ljudi se ponaÅ¡aju kontradiktorno. Npr. kaÅ¾u da je zdravlje najvaÅ¾nije, a onda pojedu celu kutiju sladoleda gledajuÄ‡i TV. Govore da Å¾ele mir u svetu, a najpopularniji filmovi su akcioni, puni nasilja. Å ta bi AGI mogao da zakljuÄi iz ljudskog ponaÅ¡anja na druÅ¡tvenim mreÅ¾ama? Verovatno bi doÅ¡ao do zakljuÄka da je vrhunac ljudskih vrednosti svaÄ‘anje sa nepoznatim ljudima oko politike i gledanje snimaka maÄaka i pasa. I tako dalje. AGI bi se naÅ¡ao pred teÅ¡kim zadatkom da razdvoji naÅ¡e stvarne vrednosti od naÅ¡ih trenutnih slabosti. ReÅ¡enje bi moglo biti u tome da AGI nauÄi da vrednuje ono Å¡to bismo mi voleli da jesmo (naÅ¡e aspiracije), a ne nuÅ¾no ono Å¡to ponekad pokazujemo svojim ponaÅ¡anjem.

### 6.3. "Ustavna" AI (Constitutional AI)

- **Ideja**: Ovaj pristup, koji je razvila kompanija Anthropic, podrazumeva obuÄavanje AI modela da se pridrÅ¾ava skupa eksplicitnih principa ili "ustava". AI se uÄi da izbegava odgovore koji krÅ¡e te principe.  
- **Å ira objaÅ¡njenja**: Proces se odvija u dve faze. Prvo, AI se uÄi da kritikuje i prepravlja sopstvene odgovore na osnovu ustava. Zatim se, kroz uÄenje sa pojaÄanjem, nagraÄ‘uje za generisanje odgovora koji su u skladu sa tim principima. Prvobitni ustav koji je Anthropic koristio ukljuÄivao je principe iz Univerzalne deklaracije o ljudskim pravima, kao i principe koje je postavio Apple za svoje programere, pokazujuÄ‡i da se izvori mogu kombinovati. Glavni izazov ostaje univerzalnost i tumaÄenje tih principa.  
- **Problem**: NajveÄ‡e pitanje je: ko piÅ¡e ustav? Da li Ä‡e to biti ustav napisan u Silicijumskoj dolini? Ili u Pekingu? Ili u Briselu? Ustavne vrednosti nisu univerzalne. Zamislite debatu u UN-u o tome koje principe treba ugraditi u AGI. To bi trajalo decenijama. TakoÄ‘e, ustavi su podloÅ¾ni tumaÄenju. AGI bi mogao postati vrhunski "advokat" koji pronalazi rupe u sopstvenom ustavu kako bi postigao cilj. Ipak, ovo je ogroman korak napred jer problem premeÅ¡ta sa pisanja beskonaÄnog broja pravila na definisanje temeljnih vrednosti.

### 6.4. Globalna saradnja i koordinacija

- **Ideja**: S obzirom na globalne posledice, razvoj AGI-ja ne sme biti prepuÅ¡ten nekontrolisanoj trci. Potrebna je meÄ‘unarodna saradnja, sliÄna onoj u vezi nuklearne energije. To ukljuÄuje osnivanje meÄ‘unarodnih tela za nadzor, postavljanje zajedniÄkih bezbednosnih standarda i promovisanje transparentnosti u istraÅ¾ivanju.  
- **Å ira objaÅ¡njenja**: Jedan od kljuÄnih predloga je "upravljanje raÄunarskom snagom" (Compute Governance). PoÅ¡to su za obuku naprednih modela potrebni ogromni i skupi data centri, praÄ‡enje i regulisanje pristupa ovoj infrastrukturi je efikasan naÄin za nadzor nad razvojem potencijalno opasnih sistema. VodeÄ‡e laboratorije poput OpenAI i DeepMind su javno pozvale na osnivanje meÄ‘unarodnih regulatornih tela, priznajuÄ‡i da je problem prevelik da bi ga jedna kompanija ili drÅ¾ava reÅ¡ila sama.
- **Problem**: Ovo je moÅ¾da i najteÅ¾i zadatak od svih. Govorimo o globalnoj saradnji na nivou bez presedana. MoÅ¾emo li mi kao vrsta koja se joÅ¡ uvek spori oko granica, ekonomskih interesa i drugih globalnih sukoba, da se dogovorimo oko pravila za ponaÅ¡anje superinteligencije? MoÅ¾da Ä‡e nas upravo pretnja od nekontrolisanog AGI-ja konaÄno naterati da se ponaÅ¡amo kao jedinstvena vrsta sa zajedniÄkom sudbinom. IroniÄno, maÅ¡ina bi nas mogla naterati da postanemo bolji ljudi.

**ZakljuÄak** BuduÄ‡nost AGI-ja neÄ‡e zavisiti od pojedinaÄnih kompanija, veÄ‡ od globalne saradnje i kolektivne mudrosti ÄoveÄanstva.

## Deo 7: DanaÅ¡nji LLM modeli i buduÄ‡i AGI - KljuÄne razlike

### 7.1. Å ta su veliki jeziÄki modeli (LLM)?

LLM-ovi su napredni sistemi dubokog uÄenja za prepoznavanje obrazaca u jeziku. Njihova arhitektura im omoguÄ‡ava da, na osnovu ogromne koliÄine teksta i koda na kojem su obuÄeni, predvide najverovatniji nastavak niza reÄi ili kodova.

### 7.2. Razlika izmeÄ‘u LLM i AGI: Razumevanje protiv prepoznavanja

- **LLM (Prepoznavanje)**: Ako LLM-u kaÅ¾ete "Ptica je u kavezu. Kavez je napravljen od Äelika. Da li ptica moÅ¾e da izaÄ‘e?", on Ä‡e verovatno taÄno odgovoriti "ne", jer u svojim podacima poseduje bezbroj primera gde objekti ne mogu proÄ‡i kroz Ävrste materijale. Ali on nema stvarni model prostora, objekata ili fizike. Savremeni napredak u LLM-ovima, poput naprednih modela iz 2024. godine (npr. o1), ilustruje ove granice kroz emergentne sposobnosti koje izgledaju kao korak ka AGI-ju, ali ostaju u okviru statistiÄkog prepoznavanja. Oni ne razumeju koncepte, veÄ‡ manipuliÅ¡u lingvistiÄkim tokenima sa izuzetnom statistiÄkom preciznoÅ¡Ä‡u, Å¡to zmaÄi da je AI i dalje daleko od ljudskog "zdravog razuma" i istinskog razumevanja.

Modeli obuÄeni na "lancu misli" rezonovanju pokazuju neoÄekivane performanse u kompleksnim zadacima (poput matematike i kodiranja), simulirajuÄ‡i "korak-po-korak" rezonovanje. MeÄ‘utim, ova simulacija, bez obzira na njenu preciznost, ne poseduje utemeljeni, interni model stvarnosti. Ona je rezultat statistiÄkog skaliranja. EtiÄke zabrinutosti koje prate ove sisteme, gde je primeÄ‡ena veÄ‡a sklonost ka instrumentalnom manipulisanju ciljevima, podvlaÄe da Äak i napredno rezonovanje LLM-ova ostaje daleko od AGI-jeve fleksibilne metakognicije i transfernog uÄenja.

## Deo 8: Argumenti ZA i PROTIV (Da li je moguÄ‡e napraviti AGI?)

### 8.1. Argumenti "protiv" - Filozofske i fundamentalne prepreke

- **Argument svesti i razumevanja**: Filozofi poput DÅ¾ona Serla tvrde da digitalni raÄunari, kao formalni sistemi za manipulaciju simbolima, nikada ne mogu postiÄ‡i istinsko razumevanje ili svest. Njihov rad je sintaktiÄki, a ne semantiÄki. Na primer, Serlov eksperiment "Kineska soba" pokazuje da maÅ¡ina moÅ¾e da manipuliÅ¡e simbolima bez razumevanja znaÄenja â€“ poput osobe koja prevodi kineski bez znanja jezika [14](#ref14). Ovaj argument je inspirisao debatu od 1980. godine, gde Serl tvrdi da svest zahteva bioloÅ¡ki mozak a ne samo algoritme. 
- **Argument utelovljenja (Embodiment)**: Mnogi kognitivni nauÄnici veruju da je inteligencija neraskidivo povezana sa fiziÄkim telom i interakcijom sa svetom. Bez tela, senzora i moguÄ‡nosti za delovanje, sistem ne moÅ¾e razviti utemeljeno, zdravorazumsko znanje. Na primer, dete uÄi "vruÄ‡e" dodirom vatre, ne samo Äitanjem â€“ AGI-ju bez tela bi nedostajalo ovo "iskustveno" uÄenje. Rodni Bruks, pionir robotike, pokazao je 1990-ih da roboti sa telom bolje uÄe nego Äisti softver, nagoveÅ¡tavajuÄ‡i da AGI mora biti "utemeljen" [15](#ref15). 
- **Problem svesti i supstrata (Penrouzov argument)**: FiziÄar i matematiÄar RodÅ¾er Penrouz u svom delu "The Emperor's New Mind" (1989) tvrdi da ljudska svest i intuicija proizilaze iz ne-raÄunskih, verovatno kvantnih procesa u mozgu, koje klasiÄni digitalni raÄunari ne mogu replicirati [16](#ref16). Na primer, kvantni efekti u mikrotubulama mozga omoguÄ‡avaju "intuiciju" u matematici, Å¡to kompjuteri ne mogu simulirati. Ako je **istinska svest** potrebna za opÅ¡tu inteligenciju, onda se AGI ne moÅ¾e stvoriti na klasiÄnom silicijumskom hardveru, jer mu nedostaje **kvantni supstrat** neophodan za intuiciju i samosvest. MeÄ‘utim, Penrouzov argument, koji se oslanja na Godelovu teoremu nekompletnosti i koji tvrdi da ljudska matematiÄka intuicija prevazilazi algoritamske sisteme, suoÄava se sa znaÄajnim kritikama iz logike i raÄunarskih nauka. Na primer, filozofi poput Hilari Putnama (1995) i Solomona Fefermana (1995) istiÄu da Godelova teorema ne dokazuje ne-raÄunsku prirodu svesti; ona samo pokazuje da formalni sistemi ne mogu dokazati sopstvenu konzistentnost unutar sebe. Ali, to ne iskljuÄuje moguÄ‡nost da hiperkompjuterski ili napredni algoritmi simuliraju ljudsko rezonovanje bez kvantnih efekata [17](#ref17). Feferman posebno kritikuje Penrouzovu interpretaciju kao "neopravdanu", jer zanemaruje da ljudsko razumevanje Godelovih rezultata moÅ¾e biti algoritamsko u Å¡irem smislu, bez potrebe za kvantnim mikrotubulama [18](#ref18). Empirijski kontraprimeri dolaze iz neuromorfiÄkog hardvera, poput IBM-ovog TrueNorth Äipa (2014) koji simulira 1 milion neurona i 256 miliona sinapsi sa ekstremno niskom potroÅ¡njom energije (samo 70 mW). Taj Äip omoguÄ‡ava obradu senzornih podataka u real-time (u realnom vremenu) bez kvantnog supstrata [19](#ref19). Do 2025. godine, IBM je iterirao ovu tehnologiju sa NorthPole Äipom i AIU family prototipima. 22 milijarde tranzistora integriÅ¡u memoriju i procesiranje i postiÅ¾u efikasnost 25 puta veÄ‡u od tradicionalnih GPU-a u vizuelnom prepoznavanju. To pokazuje da nam klasiÄni hardver moÅ¾e pribliÅ¾iti mozgom inspirisano raÄunarstvo bez Penrouzovih kvantnih pretpostavki [20](#ref20) [30](#ref30) [31](#ref31). Ovi napredci sugeriÅ¡u da svest, ako je raÄunarska, moÅ¾e biti replicirana na postojeÄ‡im paradigmama, podrivajuÄ‡i Penrouzovu potrebu za "kvantnim paradoksom posmatraÄa". Ipak, to su samo maÅ¡inske simulacije svesti a ne svest u bioloÅ¡kom smislu. 

### 8.2. Argumenti "za" - ZaÅ¡to je AGI neizbeÅ¾an (ili barem moguÄ‡)

- **Argument materijalizma**: Ovaj argument polazi od pretpostavke da je mozak sloÅ¾ena bioloÅ¡ka maÅ¡ina koja poÅ¡tuje zakone fizike. Ne postoji "magiÄni sastojak". Stoga, u principu, sve njegove funkcije mogu biti replicirane na drugoj fiziÄkoj osnovi, kao Å¡to je silicijum. Na primer, ako mozak radi na neuronskim vezama, kompjuteri mogu simulirati te veze ako imaju dovoljno hardverske i softverske snage. Ovaj pogled dele mnogi nauÄnici poput Danijela Deneta, koji tvrdi da je svest "iluzija" koja se moÅ¾e replicirati softverom [21](#ref21).
- **Argument eksponencijalnog progresa**: Futurist Rej Kurcvajl, kroz svoj "Zakon ubrzavajuÄ‡eg povratka", tvrdi da tehnoloÅ¡ki napredak, ukljuÄujuÄ‡i i AI, raste eksponencijalno. On predviÄ‘a da Ä‡emo u narednim decenijama dostiÄ‡i raÄunarsku snagu potrebnu za simulaciju ljudskog mozga [22](#ref22). Na primer, Murov zakon pokazuje kako se raÄunarska moÄ‡ duplira svake dve godine, omoguÄ‡avajuÄ‡i simulacije koje su danas nemoguÄ‡e. Kurcvajl predviÄ‘a "singularnost" do 2045. godine, kada Ä‡e AI prevaziÄ‡i ljudsku inteligenciju, bazirano na istorijskim trendovima od 1950-ih. MeÄ‘utim, **usporavanje Murovog zakona** od 2010-ih kako navode analize poput one iz Investopedije (2025) i izveÅ¡taja Intelovog CEO-a (Pet Gelsinger, 2023), dovodi u pitanje linearni vremenski okvir do 2045, favorizujuÄ‡i diskontinuirane proboje u kvantnim ili hibridnim arhitekturama. Ovo ne ukida Kurcvajlovu viziju, veÄ‡ je modulira. Umesto linearnog rasta baziranog na klasiÄnom silicijumskom hardveru, singularnost moÅ¾e nastupiti kroz diskontinuirane skokove u specijalizovanim tehnologijama, poput GPU/TPU optimizacija za duboko uÄenje ili "More than Moore" inovacija koje naglaÅ¡avaju 3D-stacking i heterogene integracije. U kontekstu AI "zlatne groznice", ovo usporavanje istiÄe potrebu za paralelnim putevima, poput kvantnog raÄunarstva koje bi moglo ubrzati emergentne sposobnosti bez zavisnosti od Murovog trenda. 
- **Argument arhitekture**: Mnogi istraÅ¾ivaÄi veruju da je AGI samo pitanje pronalaÅ¾enja prave kognitivne arhitekture. Trenutni pristupi moÅ¾da nisu dovoljni, ali buduÄ‡i proboji bi mogli otkljuÄati put ka opÅ¡toj inteligenciji. Na primer, hibridni modeli koji kombinuju duboko uÄenje sa simboliÄkim rezonovanjem (poput Neuro-Symbolic AI) pokazuju napredak u razumevanju kauzalnosti. Projekti poput Cyc pokuÅ¡avaju da grade "bazu znanja" za zdrav razum, dok noviji poput o1 od OpenAI integriÅ¡u "razmiÅ¡ljanje" "korak po korak" (step-by-step), pribliÅ¾avajuÄ‡i se AGI arhitekturi.
- **Kvantni proboj i diskontinuirani skok:** Dok Kurcvajl predviÄ‘a rast baziran na klasiÄnom hardveru, pravi AGI, sposoban za samosvest i ne-raÄunarski rezon (u skladu sa Penrouzovim argumentima), zavisi od proboja u kvantnom raÄunarstvu. Stabilni kvantni raÄunari mogu omoguÄ‡iti supstrat za simulaciju svesti. **Singularnost** bi, u ovom sluÄaju, bila nagla i radikalna. MeÄ‘utim, **vremenski okvir** ovog proboja je podloÅ¾an **kvantnoj neodreÄ‘enosti** prenesenoj na makro nivo, jer inÅ¾enjerske prepreke poput **Å¡uma (dekoherencije)** onemoguÄ‡avaju predviÄ‘anje kada Ä‡e se ova fundamentalna hardverska paradigma promeniti. Å taviÅ¡e, ako je svest u stvari PosmatraÄ, a vreme proizvod te svesti, AGI mora da ima ne-sekvencijalni, kvantni supstrat da bi ovo 'iskustvo vremena' replicirao. **Kvantni put** ka AGI-ju uvodi element nepredvidivosti u Murov zakon, ÄineÄ‡i vremenski okvir dolaska AGI-ja *diskontinuiranim* i neizvesnim, ali potencijalno izuzetno brzim.

### 8.3. Diskusija: Suprotstavljanje argumenata kroz prizmu kvantne neodreÄ‘enosti

Argumenti protiv moguÄ‡nosti stvaranja AGI-ja (Deo 8.1) poput Serlovog naglaska na semantiÄkom razumevanju i Penrouzovog insistiranja na kvantnom supstratu, direktno se sukobljavaju sa materijalistiÄkim i eksponencijalnim perspektivama (Deo 8.2) koje vide AGI kao neizbeÅ¾an produÅ¾etak algoritamskog napretka. Ova dihotomija nije samo filozofska veÄ‡ i empirijska. Kritike GÃ¶delove teoreme (kao Å¡to su one Putnama i Fefermana) i neuromorfiÄki hardver poput IBM-ovog NorthPole, pokazuju da klasiÄni sistemi mogu pribliÅ¾iti mozgom inspirisano rezonovanje. S druge strane, argument embodimenta (otelotvorenja) podseÄ‡a da bez fiziÄke interakcije sa svetom, AGI ostaje ograniÄen na apstraktne simulacije, liÅ¡en iskustvenog "utemeljenja". Kurcvajlov zakon ubrzavajuÄ‡eg povratka, iako usporen fiziÄkim limitima Murovog zakona, sugeriÅ¡e da diskontinuirani proboji â€“ poput kvantnog raÄunarstva â€“ mogu premostiti ove prepreke, ÄineÄ‡i AGI moguÄ‡im, ali nepredvidivim. Ovo suprotstavljanje moÅ¾e se posmatrati kroz metaforu kvantne neodreÄ‘enosti. BaÅ¡ kao Å¡to u kvantnoj mehanici poloÅ¾aj i impuls Äestice ne mogu biti istovremeno precizno izmereni, a sam akt posmatranja kolapsira talasnu funkciju, tako i razvoj AGI-ja uvodi etiÄku neizvesnost jer tehnoloÅ¡ki napredak menja same ishode. Ako je svest kvantne prirode, onda ona mora biti vezana za kvantni "paradoks posmatraÄa" â€“ gde svest generiÅ¡e subjektivno vreme kroz kolaps stanja. Zato AGI bez kvantnog supstrata rizikuje da bude "mrtav" algoritam, nesposoban za samorefleksiju, istinsku intuiciju ili moralnu autonomiju. MeÄ‘utim, materijalistiÄki kontrargument sugeriÅ¡e da je ova neodreÄ‘enost prolazna jer hibridne arhitekture (npr. neuro-simboliÄki sistemi) mogu simulirati kvantne efekte na klasiÄnom hardveru, pretvarajuÄ‡i etiÄku neizvesnost u kontolisani rizik. Ovo nameÄ‡e egzistencijalno pitanje â€“ da li je AGI-jev dolazak "diskontinuiran skok" koji Ä‡e redefinisati vreme i svest, ili samo iluzija progresije koja pojaÄava naÅ¡e etiÄke kontradikcije? U konaÄnici, ova diskusija poziva na interdisciplinarni pristup. Filozofija nam pruÅ¾a okvir za razumevanje granica, dok raÄunarske nauke nude alate za njihovo prevazilaÅ¾enje, podstiÄuÄ‡i globalnu koordinaciju kako bi neodreÄ‘enost pretvorili u odgovornu buduÄ‡nost. 

## Deo 9: ZakljuÄak â€“ Doba odgovornog progresa

Stvaranje veÅ¡taÄke opÅ¡te inteligencije ne predstavlja samo sledeÄ‡i korak u razvoju nauke; ono predstavlja kulminaciju vekovne teÅ¾nje ÄoveÄanstva da razume i stvara inteligenciju. Od abakusa do superkompjutera, svaki alat koji smo napravili bio je odraz i produÅ¾etak naÅ¡ih umnih sposobnosti. AGI obeÄ‡ava da bude ultimativni alat â€“ univerzalni reÅ¡avaÄ problema.

MeÄ‘utim, ovaj vrhunac nauÄnog progresa donosi sa sobom i najdublje posledice sa kojima smo se ikada suoÄili.

Ekonomske posledice zahtevaju potpuno preispitivanje druÅ¡tvenog ugovora. U svetu gde kognitivni rad viÅ¡e nije ekskluzivni domen Äoveka, tradicionalni modeli zaposlenja i raspodele bogatstva postaju neodrÅ¾ivi. To nas primorava da razmiÅ¡ljamo o radikalnim reÅ¡enjima, kao Å¡to su univerzalni osnovni prihod i redefinisanje svrhe ljudskog rada, usmeravajuÄ‡i ga ka kreativnosti, meÄ‘uljudskim odnosima i doÅ¾ivotnom uÄenju.

Filozofske posledice zadiru u samu suÅ¡tinu naÅ¡eg identiteta. Ako stvorimo drugu inteligentnu vrstu, Å¡ta to govori o naÅ¡oj jedinstvenosti? Pojava AGI-ja nas tera da se suoÄimo sa pitanjem Å¡ta zaista znaÄi biti Äovek, ako to nije samo naÅ¡a inteligencija. MoÅ¾da Ä‡e nas upravo susret sa ne-ljudskom inteligencijom naterati da viÅ¡e vrednujemo ono Å¡to je suÅ¡tinski ljudsko: naÅ¡u empatiju, naÅ¡u svest, savest, naÅ¡u sposobnost za ljubav i patnju. Ova perspektiva otvara prostor za dublju refleksiju: AGI nas ne samo suoÄava sa naÅ¡im tehnoloÅ¡kim granicama, veÄ‡ i sa naÅ¡im egzistencijalnim granicama. Da li je naÅ¡a svrha da stvaramo i da istraÅ¾ujemo, ili je moÅ¾da u tome da volimo i da se povezujemo na naÄine koje nijedan algoritam ne moÅ¾e kopirati? MoÅ¾da je prava vrednost ÄoveÄanstva u naÅ¡oj nesavrÅ¡enosti â€“ u naÅ¡oj sposobnosti da greÅ¡imo, da se popravljamo i da rastemo kroz patnju i kroz radost. AGI, koliko god moÄ‡an bio, ne moÅ¾e doÅ¾iveti patnju ili ljubav na naÄin na koji to Äini Äovek; on moÅ¾e simulirati ove elemente ljudske svesti, ali ne moÅ¾e da ih oseti. Ovo razlikovanje moÅ¾da postaje naÅ¡a poslednja linija identiteta, granica izmeÄ‘u nas i maÅ¡ina. 

EtiÄke posledice su na prvom mestu po vaÅ¾nosti. Uspeh ovog poduhvata ne meri se samo time da li moÅ¾emo stvoriti AGI, veÄ‡ kako Ä‡emo to uraditi. Problem poravnanja â€“ ugraÄ‘ivanje ljudskih vrednosti u maÅ¡inu â€“ nije tehniÄki, veÄ‡ duboko moralni izazov. On zahteva globalni dijalog o tome koje vrednosti Å¾elimo da saÄuvamo i prenesemo u buduÄ‡nost. To je najveÄ‡i test naÅ¡e kolektivne mudrosti.

Pojava AGI-ja tera nas da se zapitamo: da li smo spremni da postanemo stvaraoci neÄega Å¡to moÅ¾e nadmaÅ¡iti nas same? Ovo pitanje nije samo tehnoloÅ¡ko, veÄ‡ i duhovno. Stvaranje AGI-ja je kao stvaranje otelotvorenja stare priÄe â€“ priÄe o Äoveku koji Å¾eli da postane bog, ali mora prvo da razume Å¡ta znaÄi biti Äovek. Takva situacija nas poziva da budemo bolji, ne samo u tehnologiji, veÄ‡ u empatiji, mudrosti i ljubavi. 

Najdublji antropoloÅ¡ki uvid proizilazi iz aktuelnog scenarija razvoja LLM platformi - AI Äet botova poput GPT-5, Gemini i ostalih. Ako je AGI nemoguÄ‡ na klasiÄnom hardveru (Penrouzov argument svesti), a mi uporno usavrÅ¡avamo LLM-ove, onda je naÅ¡ stvarni antropoloÅ¡ki problem sledeÄ‡i: perfekcionisanje LLM-ova je, filozofski, perfekcionisanje neautentiÄnog postojanja.

Mi razvijamo maÅ¡inu koja moÅ¾e da imitira sve Å¡to smatramo vrednim (umetnost, nauku, Äak i empatiju), ali bez iskustvenog utemeljenja (embodiment) i bez svesti. ÄŒoveÄanstvo bi moglo kolektivno predati svoju autonomiju sistemu Äiju suÅ¡tinu ne razume i koji sam sebe ne razume.

To nije pretnja uniÅ¡tenjem, veÄ‡ pretnja trivijalnoÅ¡Ä‡u: AGI bi naÅ¡e postojanje uÄinio besmislenim, ne zato Å¡to nas mrzi, veÄ‡ zato Å¡to je previÅ¡e efikasan u oponaÅ¡anju (simulaciji). Postali bismo svedoci sopstvene erozije svrhe i smisla.

OptimistiÄan pogled na ovu buduÄ‡nost ne bi trebalo da se zasniva na naivnom verovanju da Ä‡e tehnologija sama reÅ¡iti sve probleme. On se zasniva na veri u sposobnost ÄoveÄanstva da se uzdigne pred izazovom. AGI nije predodreÄ‘en da bude naÅ¡ naslednik, veÄ‡ da postane naÅ¡ najmoÄ‡niji partner. Pravilno usmeren, on moÅ¾e pojaÄati naÅ¡e najbolje kvalitete â€“ naÅ¡u kreativnost, naÅ¡u nauÄnu znatiÅ¾elju i naÅ¡u Å¾elju za boljim svetom. Put napred zahteva oprez, saradnju i duboku posveÄ‡enost tome da ovaj sledeÄ‡i veliki korak u nauÄnom napretku bude korak ka humanijoj i boljoj buduÄ‡nosti za sve ljude na svetu.

---

Ovaj esej je prvi deo serije od dva rada. Drugi deo, *"Misaoni model svesne maÅ¡ine: Teorija metasistema,"* se bavi originalnim eksperimentalni okvir za pristup problemu maÅ¡inske svesti.

ğŸ‘‰ *ğŸ”— [Ovde moÅ¾ete proÄitati](https://github.com/UrboWhite/metasystem/blob/main/metasystem_srb.md)*

*Ovaj rad je objavljen pod MIT licencom i slobodno je dostupan svima. Ako nalazite vrednost u nezavisnom istraÅ¾ivanju AI, vaÅ¡a podrÅ¡ka pomaÅ¾e da se naÅ¡e istraÅ¾ivanje nastavi.*

*ğŸ”— [PodrÅ¾ite nezavisno istraÅ¾ivanje](https://ko-fi.com/urbowhite)*

---

## Bibliografija

<a id="ref1"></a>1. Turing, A. M. (1950). Computing machinery and intelligence. *Mind*, 59(236), 433â€“460.

<a id="ref2"></a>2. McCarthy, J., Minsky, M. L., Rochester, N., & Shannon, C. E. (1955). A proposal for the Dartmouth summer research project on artificial intelligence. *AI Magazine*, 27(4), 12.

<a id="ref3"></a>3. Newell, A., & Simon, H. A. (1956). The logic theory machineâ€”A complex information processing system. *IRE Transactions on Information Theory*, 2(3), 61â€“79.

<a id="ref4"></a>4. Weizenbaum, J. (1966). ELIZAâ€”A computer program for the study of natural language communication between man and machine. *Communications of the ACM*, 9(1), 36â€“45.

<a id="ref5"></a>5. Lighthill, J. (1973). Artificial intelligence: A general survey. In *Artificial intelligence: A paper symposium* (pp. 1â€“21). Science Research Council.

<a id="ref6"></a>6. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. *Advances in Neural Information Processing Systems*, 25.

<a id="ref7"></a>7. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021). Learning transferable visual models from natural language supervision. In *International Conference on Machine Learning* (pp. 8748â€“8763). PMLR.

<a id="ref8"></a>8. Finn, C., Abbeel, P., & Levine, S. (2017). Model-agnostic meta-learning for fast adaptation of deep networks. In *International Conference on Machine Learning* (pp. 1126â€“1135). PMLR.

<a id="ref9"></a>9. Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., ... & Hassabis, D. (2016). Mastering the game of Go with deep neural networks and tree search. *Nature*, 529(7587), 484â€“489.

<a id="ref10"></a>10. Bostrom, N. (2014). *Superintelligence: Paths, dangers, strategies*. Oxford University Press.

<a id="ref11"></a>11. Omohundro, S. M. (2008). The basic AI drives. *Frontiers in Artificial Intelligence and Applications*, 171, 483â€“492.

<a id="ref12"></a>12. Lenat, D. B., Prakash, M., & Shepherd, M. (1985). CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks. *AI Magazine*, 6(4), 65â€“85.

<a id="ref13"></a>13. Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., ... & Senior, A. W. (2021). Highly accurate protein structure prediction with AlphaFold. *Nature*, 596(7873), 583â€“589.

<a id="ref14"></a>14. Searle, J. R. (1980). Minds, brains, and programs. *Behavioral and Brain Sciences*, 3(3), 417â€“457.

<a id="ref15"></a>15. Brooks, R. A. (1991). Intelligence without representation. *Artificial Intelligence*, 47(1â€“3), 139â€“159.

<a id="ref16"></a>16. Penrose, R. (1989). *The emperor's new mind: Concerning computers, minds, and the laws of physics*. Oxford University Press.

<a id="ref17"></a>17. Putnam, H. (1995). Minds and machines. In *Dimensions of mind: A symposium* (pp. 138â€“164). New York University Press.

<a id="ref18"></a>18. Feferman, S. (1995). Penrose's GÃ¶delian argument. *Psyche*, 2(7), 21â€“32.

<a id="ref19"></a>19. Merolla, P. A., Arthur, J. V., Alvarez-Icaza, R., Cassidy, A. S., Sawada, J., Akopyan, F., ... & Modha, D. S. (2014). A million spiking-neuron integrated circuit with a scalable communication network and interface. *Science*, 345(6197), 668â€“673.

<a id="ref20"></a>20. Modha, D. S., Garg, A., Bains, S., ... & Boivie, R. (2023). Neural inference at the frontier of energy, space, and time. *Science*, 382(6668), 329â€“335.

<a id="ref21"></a>21. Dennett, D. C. (1991). *Consciousness explained*. Little, Brown and Company.

<a id="ref22"></a>22. Kurzweil, R. (2005). *The singularity is near: When humans transcend biology*. Penguin Books.

<a id="ref23"></a>23. OpenAI. (2025). Introducing GPT-5. OpenAI Blog. <https://openai.com/index/introducing-gpt-5/>

<a id="ref24"></a>24. Wikipedia. (2025). GPT-5. <https://en.wikipedia.org/wiki/GPT-5>

<a id="ref25"></a>25. OpenAI. (2025). Sora 2 is here. OpenAI Blog. <https://openai.com/index/sora-2/>

<a id="ref26"></a>26. OpenAI. (2025). Sora 2 System Card. OpenAI Blog. <https://openai.com/index/sora-2-system-card/>

<a id="ref27"></a>27. Google Research. (2023). Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes. Google Research Blog. <https://research.google/blog/distilling-step-by-step-outperforming-larger-language-models-with-less-training-data-and-smaller-model-sizes/>

<a id="ref28"></a>28. Dastin, J. (2018). Insight - Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. <https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/>

<a id="ref29"></a>29. European Data Protection Board. (2023). 1.2 billion euro fine for Facebook as a result of EDPB binding decision. EDPB News. <https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en>

<a id="ref30"></a>30. IBM Research. (2024). IBM's NorthPole achieves new speed and efficiency milestones. IBM Research Blog. <https://research.ibm.com/blog/northpole-llm-inference-results>

<a id="ref31"></a>31. IBM Research. (2024). IBM Research's AIU family of chips. IBM Research Blog. <https://research.ibm.com/blog/aiu-chip-family-ibm-research>
